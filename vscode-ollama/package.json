{
  "name": "vscode-ollama",
  "displayName": "Ollama for VS Code",
  "description": "Run Ollama models directly from VS Code - code editing, project-aware AI assistance",
  "version": "0.0.1",
  "publisher": "OllamaExtension",
  "private": true,
  "license": "MIT",
  "icon": "icons/icon-128.png",
  "engines": {
    "vscode": "^1.60.0"
  },
  "categories": [
    "Other",
    "Machine Learning",
    "Education",
    "Programming Languages"
  ],
  "activationEvents": [
    "onCommand:vscode-ollama.runModel",
    "onCommand:vscode-ollama.listModels",
    "onCommand:vscode-ollama.pullModel",
    "onCommand:vscode-ollama.checkInstallation",
    "onCommand:vscode-ollama.explainCode",
    "onCommand:vscode-ollama.improveCode",
    "onCommand:vscode-ollama.generateDocumentation",
    "onCommand:vscode-ollama.debug"
  ],
  "main": "./dist/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "vscode-ollama.debug",
        "title": "Ollama: Debug Extension"
      },
      {
        "command": "vscode-ollama.runModel",
        "title": "Ollama: Run Model"
      },
      {
        "command": "vscode-ollama.listModels",
        "title": "Ollama: List Models"
      },
      {
        "command": "vscode-ollama.pullModel",
        "title": "Ollama: Download/Install Model"
      },
      {
        "command": "vscode-ollama.checkInstallation",
        "title": "Ollama: Check Installation"
      },
      {
        "command": "vscode-ollama.explainCode",
        "title": "Ollama: Explain Selected Code"
      },
      {
        "command": "vscode-ollama.improveCode",
        "title": "Ollama: Improve Selected Code"
      },
      {
        "command": "vscode-ollama.generateDocumentation",
        "title": "Ollama: Generate Documentation for Selection"
      },
      {
        "command": "vscode-ollama.cancelRequest",
        "title": "Ollama: Cancel Current Request"
      }
    ],
    "menus": {
      "editor/context": [
        {
          "when": "editorHasSelection",
          "command": "vscode-ollama.explainCode",
          "group": "1_ollama@1"
        },
        {
          "when": "editorHasSelection",
          "command": "vscode-ollama.improveCode",
          "group": "1_ollama@2"
        },
        {
          "when": "editorHasSelection",
          "command": "vscode-ollama.generateDocumentation",
          "group": "1_ollama@3"
        }
      ]
    },
    "configuration": {
      "title": "Ollama",
      "properties": {
        "ollama.apiUrl": {
          "type": "string",
          "default": "http://localhost:11434",
          "description": "URL of the Ollama API server"
        },
        "ollama.defaultModel": {
          "type": "string",
          "default": "",
          "description": "Default model to use when not specified"
        },
        "ollama.includeProjectContext": {
          "type": "boolean",
          "default": true,
          "description": "Automatically include project context in prompts"
        },
        "ollama.showFileExplorer": {
          "type": "boolean",
          "default": false,
          "description": "Show project file explorer panel by default"
        },
        "ollama.filePatterns": {
          "type": "array",
          "default": [
            "**/*.js",
            "**/*.ts",
            "**/*.jsx",
            "**/*.tsx",
            "**/*.py",
            "**/*.html",
            "**/*.css",
            "**/*.json",
            "**/README.md"
          ],
          "description": "File patterns to include in project context"
        },
        "ollama.excludePatterns": {
          "type": "array",
          "default": [
            "**/node_modules/**",
            "**/dist/**",
            "**/build/**",
            "**/.git/**"
          ],
          "description": "File patterns to exclude from project context"
        },
        "ollama.maxResponseTokens": {
          "type": "number",
          "default": 4096,
          "description": "Maximum number of tokens in model responses"
        },
        "ollama.autoStartServer": {
          "type": "boolean",
          "default": true,
          "description": "Automatically start Ollama server if not running"
        },
        "ollama.saveConversationHistory": {
          "type": "boolean",
          "default": true,
          "description": "Save conversation history between sessions"
        },
        "ollama.codeActionsEnabled": {
          "type": "boolean",
          "default": true,
          "description": "Enable code action buttons (copy, apply) in responses"
        },
        "ollama.statusBarPolling": {
          "type": "boolean",
          "default": true,
          "description": "Periodically check and update Ollama status in the status bar"
        },
        "ollama.forceRecheck": {
          "type": "boolean",
          "default": false,
          "description": "Force recheck of Ollama status even if cached (for troubleshooting)"
        },
        "ollama.temperature": {
          "type": "number",
          "default": 0.7,
          "minimum": 0,
          "maximum": 2,
          "description": "Temperature setting for model generation (0.0-2.0, lower = more deterministic)"
        },
        "ollama.requestTimeout": {
          "type": "number",
          "default": 90,
          "minimum": 15,
          "maximum": 300,
          "description": "Timeout in seconds for requests to the Ollama server"
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "webpack --mode production",
    "compile": "webpack",
    "watch": "webpack --watch",
    "package": "vsce package",
    "lint": "eslint src --ext ts",
    "test": "node ./out/test/runTest.js"
  },
  "devDependencies": {
    "@types/glob": "^7.1.3",
    "@types/node": "^14.14.37",
    "@types/vscode": "^1.60.0",
    "@typescript-eslint/eslint-plugin": "^5.30.0",
    "@typescript-eslint/parser": "^5.30.0",
    "canvas": "^3.1.0",
    "copy-webpack-plugin": "^13.0.0",
    "eslint": "^8.13.0",
    "glob": "^7.1.6",
    "terser-webpack-plugin": "^5.3.14",
    "ts-loader": "^9.3.0",
    "typescript": "^4.7.4",
    "webpack": "^5.70.0",
    "webpack-cli": "^4.9.2"
  },
  "dependencies": {
    "axios": "^0.27.2"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/yourusername/vscode-ollama"
  },
  "keywords": [
    "ollama",
    "ai",
    "llm",
    "machine learning",
    "language model",
    "code assistant",
    "ai coding",
    "cursor",
    "code editing",
    "llama",
    "mistral",
    "phi",
    "gemma"
  ],
  "author": "Ollama Extension Team",
  "bugs": {
    "url": "https://github.com/yourusername/vscode-ollama/issues"
  },
  "homepage": "https://github.com/yourusername/vscode-ollama#readme"
}
