{
  "name": "vscode-ollama-enhanced",
  "displayName": "Ollama Enhanced for VS Code",
  "description": "Enhanced Ollama integration for VS Code with embedded models, improved performance, code selection handling, and project-aware AI assistance",
  "version": "1.3.2",
  "publisher": "CarlosPacheco",
  "private": true,
  "license": "MIT",
  "icon": "icons/icon-128.png",
  "engines": {
    "vscode": "^1.60.0"
  },
  "categories": [
    "Other",
    "Machine Learning",
    "Education",
    "Programming Languages"
  ],
  "activationEvents": [
    "onStartupFinished",
    "onCommand:vscode-ollama-enhanced.runModel",
    "onCommand:vscode-ollama-enhanced.listModels",
    "onCommand:vscode-ollama-enhanced.pullModel",
    "onCommand:vscode-ollama-enhanced.installEmbeddedModel",
    "onCommand:vscode-ollama-enhanced.switchOllamaMode",
    "onCommand:vscode-ollama-enhanced.checkInstallation",
    "onCommand:vscode-ollama-enhanced.explainCode",
    "onCommand:vscode-ollama-enhanced.improveCode",
    "onCommand:vscode-ollama-enhanced.generateDocumentation",
    "onCommand:vscode-ollama-enhanced.debug",
    "onCommand:vscode-ollama-enhanced.addAsReference",
    "onView:ollamaEnhancedChat"
  ],
  "main": "./dist/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "vscode-ollama-enhanced.debug",
        "title": "Ollama Enhanced: Debug Extension"
      },
      {
        "command": "vscode-ollama-enhanced.runModel",
        "title": "Ollama Enhanced: Run Model"
      },
      {
        "command": "vscode-ollama-enhanced.listModels",
        "title": "Ollama Enhanced: List Models"
      },
      {
        "command": "vscode-ollama-enhanced.pullModel",
        "title": "Ollama Enhanced: Download/Install Model"
      },
      {
        "command": "vscode-ollama-enhanced.installEmbeddedModel",
        "title": "Ollama Enhanced: Install Embedded Model"
      },
      {
        "command": "vscode-ollama-enhanced.switchOllamaMode",
        "title": "Ollama Enhanced: Switch Mode (System/Embedded)"
      },
      {
        "command": "vscode-ollama-enhanced.checkInstallation",
        "title": "Ollama Enhanced: Check Installation"
      },
      {
        "command": "vscode-ollama-enhanced.explainCode",
        "title": "Ollama Enhanced: Explain Selected Code"
      },
      {
        "command": "vscode-ollama-enhanced.improveCode",
        "title": "Ollama Enhanced: Improve Selected Code"
      },
      {
        "command": "vscode-ollama-enhanced.generateDocumentation",
        "title": "Ollama Enhanced: Generate Documentation for Selection"
      },
      {
        "command": "vscode-ollama-enhanced.addAsReference",
        "title": "Ollama Enhanced: Add Selection as Reference"
      },
      {
        "command": "vscode-ollama-enhanced.cancelRequest",
        "title": "Ollama Enhanced: Cancel Current Request"
      }
    ],
    "menus": {
      "editor/context": [
        {
          "when": "editorHasSelection",
          "command": "vscode-ollama-enhanced.explainCode",
          "group": "1_ollama_enhanced@1"
        },
        {
          "when": "editorHasSelection",
          "command": "vscode-ollama-enhanced.improveCode",
          "group": "1_ollama_enhanced@2"
        },
        {
          "when": "editorHasSelection",
          "command": "vscode-ollama-enhanced.generateDocumentation",
          "group": "1_ollama_enhanced@3"
        },
        {
          "when": "editorHasSelection",
          "command": "vscode-ollama-enhanced.addAsReference",
          "group": "1_ollama_enhanced@4"
        }
      ]
    },
    "configuration": {
      "title": "Ollama Enhanced",
      "properties": {
        "ollamaEnhanced.apiUrl": {
          "type": "string",
          "default": "http://localhost:11434",
          "description": "URL of the Ollama API server (used for system mode only)"
        },
        "ollamaEnhanced.mode": {
          "type": "string",
          "enum": [
            "system",
            "embedded",
            "auto"
          ],
          "enumDescriptions": [
            "Use system-installed Ollama only",
            "Use embedded Ollama bundled with the extension",
            "Auto-detect: use embedded if system is not available"
          ],
          "default": "embedded",
          "description": "Ollama operation mode"
        },
        "ollamaEnhanced.defaultModel": {
          "type": "string",
          "default": "deepseek-coder-v2:latest",
          "description": "Default model to use when not specified"
        },
        "ollamaEnhanced.embeddedPort": {
          "type": "number",
          "default": 9527,
          "description": "Port for embedded Ollama server (must be different from system Ollama port)"
        },
        "ollamaEnhanced.includeProjectContext": {
          "type": "boolean",
          "default": true,
          "description": "Automatically include project context in prompts"
        },
        "ollamaEnhanced.showFileExplorer": {
          "type": "boolean",
          "default": false,
          "description": "Show project file explorer panel by default"
        },
        "ollamaEnhanced.filePatterns": {
          "type": "array",
          "default": [
            "**/*.js",
            "**/*.ts",
            "**/*.jsx",
            "**/*.tsx",
            "**/*.py",
            "**/*.html",
            "**/*.css",
            "**/*.json",
            "**/README.md"
          ],
          "description": "File patterns to include in project context"
        },
        "ollamaEnhanced.excludePatterns": {
          "type": "array",
          "default": [
            "**/node_modules/**",
            "**/dist/**",
            "**/build/**",
            "**/.git/**"
          ],
          "description": "File patterns to exclude from project context"
        },
        "ollamaEnhanced.maxResponseTokens": {
          "type": "number",
          "default": 4096,
          "description": "Maximum number of tokens in model responses"
        },
        "ollamaEnhanced.autoStartServer": {
          "type": "boolean",
          "default": true,
          "description": "Automatically start Ollama server if not running"
        },
        "ollamaEnhanced.saveConversationHistory": {
          "type": "boolean",
          "default": true,
          "description": "Save conversation history between sessions"
        },
        "ollamaEnhanced.codeActionsEnabled": {
          "type": "boolean",
          "default": true,
          "description": "Enable code action buttons (copy, apply) in responses"
        },
        "ollamaEnhanced.statusBarPolling": {
          "type": "boolean",
          "default": true,
          "description": "Periodically check and update Ollama status in the status bar"
        },
        "ollamaEnhanced.forceRecheck": {
          "type": "boolean",
          "default": false,
          "description": "Force recheck of Ollama status even if cached (for troubleshooting)"
        },
        "ollamaEnhanced.temperature": {
          "type": "number",
          "default": 0.7,
          "minimum": 0,
          "maximum": 2,
          "description": "Temperature setting for model generation (0.0-2.0, lower = more deterministic)"
        },
        "ollamaEnhanced.requestTimeout": {
          "type": "number",
          "default": 300,
          "minimum": 15,
          "maximum": 1200,
          "description": "Timeout in seconds for requests to the Ollama server (longer timeouts allow for more content generation)"
        },
        "ollamaEnhanced.embeddedModelsAutoUpdate": {
          "type": "boolean",
          "default": true,
          "description": "Automatically check for updates to embedded models"
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "webpack --mode production",
    "compile": "webpack",
    "watch": "webpack --watch",
    "package": "vsce package",
    "lint": "eslint src --ext ts",
    "test": "node ./out/test/runTest.js"
  },
  "devDependencies": {
    "@types/glob": "^7.1.3",
    "@types/node": "^14.14.37",
    "@types/vscode": "^1.60.0",
    "@typescript-eslint/eslint-plugin": "^5.30.0",
    "@typescript-eslint/parser": "^5.30.0",
    "canvas": "^3.1.0",
    "copy-webpack-plugin": "^13.0.0",
    "eslint": "^8.13.0",
    "glob": "^7.1.6",
    "terser-webpack-plugin": "^5.3.14",
    "ts-loader": "^9.3.0",
    "typescript": "^4.7.4",
    "webpack": "^5.70.0",
    "webpack-cli": "^4.9.2"
  },
  "dependencies": {
    "axios": "^1.6.7"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/CarlosPacheco/vscode-ollama"
  },
  "keywords": [
    "ollama",
    "ai",
    "llm",
    "machine learning",
    "language model",
    "code assistant",
    "ai coding",
    "cursor",
    "code editing",
    "llama",
    "mistral",
    "phi",
    "gemma"
  ],
  "author": "Ollama Extension Team",
  "bugs": {
    "url": "https://github.com/CarlosPacheco/vscode-ollama/issues"
  },
  "homepage": "https://github.com/CarlosPacheco/vscode-ollama#readme"
}